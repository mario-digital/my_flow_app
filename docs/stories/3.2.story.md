# Story 3.2: Conversation Storage & Retrieval (MongoDB)

## Status
Draft

## Story

**As a** backend developer,
**I want** conversation history stored in MongoDB with message threading,
**so that** users can review past conversations and maintain context.

## Acceptance Criteria

1. **Pydantic models created in `my_flow_api/src/models/conversation.py`:**
   - `Message` model: `role` (Literal["user", "assistant", "system"]), `content` (str), `timestamp` (datetime)
   - `Conversation` model: `id` (ObjectId), `context_id` (ObjectId), `messages` (List[Message]), `created_at`, `updated_at`
   - Validators for role enum and message content length

2. **Repository created in `my_flow_api/src/repositories/conversation_repository.py`:**
   - `ConversationRepository` class with methods:
     - `create_conversation(context_id: str) -> ConversationInDB`
     - `get_conversation_by_id(conversation_id: str) -> Optional[ConversationInDB]`
     - `get_conversations_by_context(context_id: str) -> List[ConversationInDB]`
     - `append_message(conversation_id: str, message: Message) -> ConversationInDB`
     - `get_recent_messages(conversation_id: str, limit: int = 20) -> List[Message]`

3. **MongoDB indexes:**
   - Conversations collection: Index on `context_id`, compound index on `(context_id, updated_at desc)`
   - Efficient retrieval of recent conversations per context

4. **Integration tests created in `my_flow_api/tests/integration/test_conversation_repository.py`:**
   - Tests conversation creation and message appending
   - Tests retrieval of recent messages
   - Tests pagination
   - At least 85% coverage

## Tasks / Subtasks

- [ ] **Task 0: Create Pydantic models for conversations** (AC: 1)
  - [ ] Create `my_flow_api/src/models/conversation.py`
  - [ ] Import required dependencies: `from pydantic import BaseModel, Field, field_validator` and `from datetime import datetime` and `from typing import Literal, List, Optional`
  - [ ] Define `MessageRole` enum class:
    ```python
    from enum import Enum

    class MessageRole(str, Enum):
        USER = "user"
        ASSISTANT = "assistant"
        SYSTEM = "system"
    ```
  - [ ] Define `Message` Pydantic model with fields:
    - `role: MessageRole` - Message sender role
    - `content: str` - Message text content with `Field(min_length=1, max_length=10000)`
    - `timestamp: datetime` - When message was created
  - [ ] Add `model_config` to enable validation and populate by name
  - [ ] Define `ConversationBase` model with common fields:
    - `context_id: str` - Parent context reference
    - `messages: List[Message] = []` - Message history
  - [ ] Define `ConversationCreate` model (inherits `ConversationBase`):
    - `context_id: str` - Required context ID
  - [ ] Define `Conversation` model (inherits `ConversationBase`) with DB fields:
    - `id: str = Field(alias="_id")` - MongoDB ObjectId as string
    - `user_id: str` - Owner of conversation
    - `created_at: datetime`
    - `updated_at: datetime`
  - [ ] Add field validator for `content` to ensure non-empty messages
  - [ ] Follow coding standards (Section 9: Backend Enum Usage)

- [ ] **Task 1: Create conversation repository with base CRUD** (AC: 2)
  - [ ] Create `my_flow_api/src/repositories/conversation_repository.py`
  - [ ] Import required modules:
    ```python
    from motor.motor_asyncio import AsyncIOMotorDatabase
    from bson import ObjectId
    from datetime import datetime
    from typing import Optional, List
    from src.models.conversation import Conversation, Message, ConversationCreate
    from src.repositories.base import BaseRepository
    ```
  - [ ] Create `ConversationRepository` class inheriting from `BaseRepository[Conversation]`
  - [ ] Implement `__init__` method that calls `super().__init__(db, "conversations", Conversation)`
  - [ ] Ensure repository follows repository pattern from backend architecture
  - [ ] Add docstrings to class and all methods

- [ ] **Task 2: Implement create_conversation method** (AC: 2)
  - [ ] Add `async def create_conversation(self, context_id: str, user_id: str) -> Conversation` method
  - [ ] Create document dictionary with:
    - `context_id: str`
    - `user_id: str`
    - `messages: []` (empty list)
    - `created_at: datetime.utcnow()`
    - `updated_at: datetime.utcnow()`
  - [ ] Call `self.collection.insert_one()` to insert document
  - [ ] Fetch inserted document with `self.collection.find_one({"_id": result.inserted_id})`
  - [ ] Convert `_id` ObjectId to string before returning
  - [ ] Return `Conversation` instance constructed from document
  - [ ] Add error handling for database errors

- [ ] **Task 3: Implement get_conversation_by_id method** (AC: 2)
  - [ ] Add `async def get_conversation_by_id(self, conversation_id: str) -> Optional[Conversation]` method
  - [ ] Convert `conversation_id` string to `ObjectId(conversation_id)`
  - [ ] Call `await self.collection.find_one({"_id": ObjectId(conversation_id)})`
  - [ ] Return `None` if not found
  - [ ] Convert `_id` to string and return `Conversation(**doc)` if found
  - [ ] Handle `InvalidId` exception from invalid ObjectId strings

- [ ] **Task 4: Implement get_conversations_by_context method** (AC: 2)
  - [ ] Add `async def get_conversations_by_context(self, context_id: str, limit: int = 10) -> List[Conversation]` method
  - [ ] Query: `{"context_id": context_id}`
  - [ ] Sort by `updated_at` descending (most recent first)
  - [ ] Limit results to `limit` parameter (default 10)
  - [ ] Use `cursor = self.collection.find(query).sort("updated_at", -1).limit(limit)`
  - [ ] Convert cursor to list: `docs = await cursor.to_list(length=limit)`
  - [ ] Convert each doc's `_id` to string
  - [ ] Return list of `Conversation` objects

- [ ] **Task 5: Implement append_message method** (AC: 2)
  - [ ] Add `async def append_message(self, conversation_id: str, message: Message) -> Conversation` method
  - [ ] Validate conversation exists with `get_conversation_by_id(conversation_id)`
  - [ ] Raise `ValueError` if conversation not found
  - [ ] Set message timestamp if not provided: `message.timestamp = datetime.utcnow()`
  - [ ] Use `$push` operator to append message to `messages` array
  - [ ] Update `updated_at` field with `$set`
  - [ ] Call `await self.collection.find_one_and_update()` with `return_document=True`
  - [ ] Convert `_id` to string and return updated `Conversation`

- [ ] **Task 6: Implement get_recent_messages method** (AC: 2)
  - [ ] Add `async def get_recent_messages(self, conversation_id: str, limit: int = 20) -> List[Message]` method
  - [ ] Fetch conversation with `get_conversation_by_id(conversation_id)`
  - [ ] Return empty list if conversation not found
  - [ ] Use array slicing to get last `limit` messages: `conversation.messages[-limit:]`
  - [ ] Return list of `Message` objects in chronological order (oldest to newest)
  - [ ] Add docstring explaining message ordering

- [ ] **Task 7: Add MongoDB indexes for conversations collection** (AC: 3)
  - [ ] Open `my_flow_api/src/database.py`
  - [ ] Locate `create_indexes()` function
  - [ ] Add index creation for conversations collection:
    ```python
    # Conversations collection indexes
    await db.conversations.create_index("context_id")
    await db.conversations.create_index([("context_id", 1), ("updated_at", -1)])
    await db.conversations.create_index("user_id")
    ```
  - [ ] Ensure indexes are created on app startup
  - [ ] Verify index creation doesn't cause errors if indexes already exist (MongoDB handles this automatically)

- [ ] **Task 8: Write integration tests for conversation creation** (AC: 4)
  - [ ] Create `my_flow_api/tests/integration/test_conversation_repository.py`
  - [ ] Import pytest, pytest fixtures, and required modules
  - [ ] Create pytest fixture `conversation_repo(db)` that returns `ConversationRepository(db)`
  - [ ] Test: `test_create_conversation_success()` - Verifies conversation is created with empty messages
  - [ ] Test: `test_create_conversation_has_timestamps()` - Verifies `created_at` and `updated_at` are set
  - [ ] Test: `test_create_conversation_links_to_context()` - Verifies `context_id` is stored correctly
  - [ ] Use `@pytest.mark.asyncio` decorator for async tests
  - [ ] Clean up test data after each test

- [ ] **Task 9: Write integration tests for message operations** (AC: 4)
  - [ ] Test: `test_append_message_to_conversation()` - Appends message and verifies it's stored
  - [ ] Test: `test_append_multiple_messages()` - Appends 3 messages and verifies order
  - [ ] Test: `test_append_message_updates_timestamp()` - Verifies `updated_at` changes after append
  - [ ] Test: `test_append_message_to_nonexistent_conversation()` - Raises `ValueError`
  - [ ] Test: `test_get_recent_messages()` - Appends 25 messages, retrieves last 20
  - [ ] Test: `test_get_recent_messages_respects_limit()` - Tests custom limit parameter
  - [ ] Verify messages are returned in chronological order (oldest to newest)

- [ ] **Task 10: Write integration tests for retrieval operations** (AC: 4)
  - [ ] Test: `test_get_conversation_by_id()` - Fetches conversation by ID successfully
  - [ ] Test: `test_get_conversation_by_id_not_found()` - Returns None for invalid ID
  - [ ] Test: `test_get_conversations_by_context()` - Fetches all conversations for a context
  - [ ] Test: `test_get_conversations_by_context_sorted()` - Verifies most recently updated first
  - [ ] Test: `test_get_conversations_by_context_limit()` - Creates 15 conversations, limits to 10
  - [ ] Test: `test_get_conversations_empty_context()` - Returns empty list for context with no conversations

- [ ] **Task 11: Write integration tests for message role validation** (AC: 1, 4)
  - [ ] Test: `test_message_role_validation()` - Accepts valid roles (user, assistant, system)
  - [ ] Test: `test_message_role_invalid_value()` - Rejects invalid role string
  - [ ] Test: `test_message_content_length_validation()` - Rejects content > 10000 chars
  - [ ] Test: `test_message_content_empty_validation()` - Rejects empty content string
  - [ ] Use Pydantic's `ValidationError` to catch validation failures
  - [ ] Verify error messages are user-friendly

- [ ] **Task 12: Run tests and verify coverage** (AC: 4)
  - [ ] Run integration tests: `cd my_flow_api && poetry run pytest tests/integration/test_conversation_repository.py -v`
  - [ ] Run coverage: `poetry run pytest tests/integration/test_conversation_repository.py --cov=src/repositories/conversation_repository --cov=src/models/conversation --cov-report=term-missing`
  - [ ] Verify coverage ≥ 85%
  - [ ] Fix any failing tests or coverage gaps
  - [ ] Document coverage report in story completion notes

- [ ] **Task 13: Code quality and compliance** (AC: All)
  - [ ] Run linter: `cd my_flow_api && poetry run ruff check src/models/conversation.py src/repositories/conversation_repository.py`
  - [ ] Fix any linting errors or warnings
  - [ ] Run type checker: `poetry run mypy src/models/conversation.py src/repositories/conversation_repository.py`
  - [ ] Fix any type errors
  - [ ] Verify import order follows coding standards (stdlib → third-party → local)
  - [ ] Verify all functions have docstrings with parameter descriptions
  - [ ] Verify exception handling follows standards (Section 5: Error Handling)
  - [ ] Verify all async functions use proper async/await patterns

## Dev Notes

### Previous Story Insights

Story 3.1 created the AI service layer with streaming support for OpenAI and Anthropic. The `Message` model defined in this story (3.2) will be used by the AI service's `stream_chat_response()` method. Ensure compatibility with the `List[Message]` parameter expected by `AIService.stream_chat_response()`.

[Source: docs/stories/3.1.story.md]

---

### Data Models: Conversation & Message

**Conversation Model:**
- `id`: string (MongoDB ObjectId) - Unique identifier
- `context_id`: string (MongoDB ObjectId) - Parent context reference
- `user_id`: string - Owner (from Logto JWT)
- `messages`: Message[] - Array of message objects
- `created_at`: datetime - Creation timestamp
- `updated_at`: datetime - Last modification timestamp

**Message Structure:**
```python
class MessageRole(str, Enum):
    USER = "user"
    ASSISTANT = "assistant"
    SYSTEM = "system"

class Message(BaseModel):
    role: MessageRole
    content: str = Field(min_length=1, max_length=10000)
    timestamp: datetime
```

**Key Points:**
- Messages are embedded documents within conversations (not separate collection)
- Message order preserved in array (chronological)
- `updated_at` changes whenever new message appended
- Future: `metadata` field for `flow_ids` and `tokens_used` (Story 3.3)

[Source: docs/architecture/data-models.md#conversation-model]

---

### MongoDB Indexes for Conversations

**Required Indexes:**
```python
# Conversations collection
await db.conversations.create_index("context_id")
await db.conversations.create_index([("context_id", 1), ("updated_at", -1)])
await db.conversations.create_index("user_id")
```

**Index Purposes:**
- `context_id`: Fast lookup of all conversations in a context
- `(context_id, updated_at desc)`: Sorted retrieval of recent conversations
- `user_id`: User-level conversation queries (future)

**Performance:**
- Compound index on `(context_id, updated_at)` supports both filtering and sorting
- Descending order (`-1`) for `updated_at` returns most recent first
- Single-field indexes used for exact match queries

[Source: docs/architecture/data-models.md#database-indexes-mongodb]

---

### Repository Pattern: Conversation Repository

**Repository Layer Responsibilities:**
- Encapsulate MongoDB CRUD operations
- Return Pydantic model instances (not raw dicts)
- Handle ObjectId ↔ string conversions
- Provide query methods with filters and pagination

**ConversationRepository Methods:**
```python
class ConversationRepository(BaseRepository[Conversation]):
    async def create_conversation(context_id: str, user_id: str) -> Conversation
    async def get_conversation_by_id(conversation_id: str) -> Optional[Conversation]
    async def get_conversations_by_context(context_id: str, limit: int = 10) -> List[Conversation]
    async def append_message(conversation_id: str, message: Message) -> Conversation
    async def get_recent_messages(conversation_id: str, limit: int = 20) -> List[Message]
```

**Key Patterns:**
- Inherit from `BaseRepository[Conversation]` for common CRUD
- Override or extend methods as needed
- Use `$push` operator for appending messages to array
- Use `find_one_and_update(..., return_document=True)` for atomic updates
- Convert `_id` ObjectId to string before returning to caller

[Source: docs/architecture/backend-architecture.md#repository-layer-data-access]

---

### Message Appending with MongoDB Array Operators

**Atomic Message Append:**
```python
result = await self.collection.find_one_and_update(
    {"_id": ObjectId(conversation_id)},
    {
        "$push": {"messages": message.model_dump()},
        "$set": {"updated_at": datetime.utcnow()}
    },
    return_document=True
)
```

**Why use `$push`:**
- Atomic operation - no race conditions
- Appends to end of array (maintains chronological order)
- Concurrent message appends are safe

**Why use `find_one_and_update`:**
- Returns updated document in single DB roundtrip
- `return_document=True` returns document AFTER update
- Avoids separate `find_one()` call after update

[Source: Motor documentation, MongoDB array operators]

---

### Array Slicing for Recent Messages

**Getting Last N Messages:**
```python
# Python list slicing (in-memory)
conversation.messages[-limit:]  # Last 'limit' messages

# MongoDB projection (future optimization)
await db.conversations.find_one(
    {"_id": ObjectId(conversation_id)},
    {"messages": {"$slice": -20}}  # Last 20 messages only
)
```

**Current Approach (Story 3.2):**
- Fetch entire conversation, slice in Python
- Simple and works for MVP (< 100 messages per conversation)

**Future Optimization (if needed):**
- Use MongoDB `$slice` projection to fetch only last N messages
- Reduces network transfer for long conversations (> 500 messages)
- Implement if performance profiling shows bottleneck

[Source: docs/architecture/backend-architecture.md#repository-layer]

---

### Pydantic Model Configuration

**Pydantic Settings Pattern:**
```python
from pydantic import BaseModel, Field, ConfigDict

class Conversation(BaseModel):
    id: str = Field(alias="_id")
    context_id: str
    user_id: str
    messages: List[Message] = []
    created_at: datetime
    updated_at: datetime

    model_config = ConfigDict(
        populate_by_name=True,  # Allows both 'id' and '_id' as input
        json_encoders={datetime: lambda v: v.isoformat()}
    )
```

**Key Configuration:**
- `alias="_id"`: Maps MongoDB `_id` field to Python `id` attribute
- `populate_by_name=True`: Accepts both `id` and `_id` in input data
- `json_encoders`: Serializes datetime to ISO 8601 strings for JSON responses

[Source: docs/architecture/backend-architecture.md#pydantic-models]

---

### Error Handling for Repositories

**Repository Error Patterns:**
```python
# Invalid ObjectId
try:
    obj_id = ObjectId(conversation_id)
except InvalidId:
    raise ValueError(f"Invalid conversation ID: {conversation_id}")

# Document not found
conversation = await self.get_conversation_by_id(conversation_id)
if not conversation:
    raise ValueError(f"Conversation not found: {conversation_id}")

# Database errors
try:
    await self.collection.insert_one(doc)
except PyMongoError as e:
    logger.error(f"Failed to create conversation: {e}")
    raise
```

**Error Handling Standards:**
- Raise `ValueError` for invalid input (caller's fault)
- Re-raise `PyMongoError` for database errors (system fault)
- Log errors server-side with context
- Never expose internal error details to API responses

[Source: docs/architecture/coding-standards.md#error-handling-standards]

---

### Async/Await Patterns for MongoDB

**Motor (Async MongoDB Driver):**
```python
# ✅ CORRECT: Use await for all Motor operations
result = await self.collection.insert_one(doc)
doc = await self.collection.find_one({"_id": obj_id})
cursor = self.collection.find(query)
docs = await cursor.to_list(length=100)

# ❌ WRONG: Forgetting await
doc = self.collection.find_one({"_id": obj_id})  # Returns coroutine, not doc!
```

**Key Points:**
- All Motor database operations return coroutines (must use `await`)
- Cursors are synchronous but `.to_list()` is async
- Use `async def` for all repository methods
- Enable `pytest-asyncio` for testing async methods

[Source: docs/architecture/tech-stack.md#database-driver, Motor documentation]

---

### File Locations (Project Structure)

**Files to Create:**
- `my_flow_api/src/models/conversation.py` - Pydantic models
- `my_flow_api/src/repositories/conversation_repository.py` - Repository implementation
- `my_flow_api/tests/integration/test_conversation_repository.py` - Integration tests

**Files to Modify:**
- `my_flow_api/src/database.py` - Add conversation collection indexes

**Files to Reference (DO NOT MODIFY):**
- `my_flow_api/src/repositories/base.py` - BaseRepository pattern
- `my_flow_api/src/database.py` - Database connection setup
- `docs/architecture/data-models.md` - Conversation model specification

[Source: docs/architecture/source-tree.md#backend-structure]

---

## Testing

### Test File Organization

**Integration Tests:**
```
my_flow_api/tests/integration/
└── test_conversation_repository.py
```

**Why Integration Tests (not Unit Tests):**
- Repository layer interacts directly with MongoDB
- Mocking MongoDB would test mock behavior, not real DB operations
- Integration tests catch index issues, query performance, schema mismatches
- Requires test MongoDB instance (Docker or MongoDB Atlas free tier)

[Source: docs/architecture/13-testing-strategy.md#test-organization]

---

### Pytest Configuration for Integration Tests

**pytest.ini settings:**
```ini
[pytest]
testpaths = tests
asyncio_mode = auto  # Auto-detect async tests
markers =
    integration: Integration tests (DB, external services)
```

**Test Fixtures:**
```python
import pytest
from motor.motor_asyncio import AsyncIOMotorClient
from src.database import get_database

@pytest.fixture
async def db():
    """Test database fixture."""
    client = AsyncIOMotorClient("mongodb://localhost:27017")
    db = client["myflow_test"]
    yield db
    # Cleanup: Drop test database after tests
    await client.drop_database("myflow_test")
    client.close()

@pytest.fixture
def conversation_repo(db):
    """ConversationRepository fixture."""
    return ConversationRepository(db)
```

**Running Integration Tests:**
```bash
# Run all integration tests
poetry run pytest tests/integration/ -v

# Run specific test file
poetry run pytest tests/integration/test_conversation_repository.py -v

# Run with coverage
poetry run pytest tests/integration/ --cov=src/repositories --cov=src/models --cov-report=term-missing
```

[Source: docs/architecture/13-testing-strategy.md#backend-tests]

---

### Coverage Requirements

**Target Coverage:**
- **Repository:** ≥ 85% line coverage
- **Pydantic Models:** ≥ 80% (validators, serialization)

**Coverage Thresholds:**
```bash
pytest --cov=src/repositories/conversation_repository \
       --cov=src/models/conversation \
       --cov-report=term-missing \
       --cov-fail-under=85
```

**What to Test:**
- All repository methods (create, read, update)
- Pydantic validators (role enum, content length)
- Error handling (invalid IDs, not found, validation errors)
- Edge cases (empty conversations, message limits, pagination)

[Source: docs/architecture/13-testing-strategy.md#test-coverage-requirements]

---

### Type Hints and mypy

**Critical Type Hints:**
```python
# All functions must have complete type annotations
async def get_conversation_by_id(self, conversation_id: str) -> Optional[Conversation]:
    ...

async def get_conversations_by_context(self, context_id: str, limit: int = 10) -> List[Conversation]:
    ...

async def append_message(self, conversation_id: str, message: Message) -> Conversation:
    ...
```

**mypy Strict Mode:**
- Run `mypy src/models/conversation.py src/repositories/conversation_repository.py`
- Use `str | None` instead of `Optional[str]` (Python 3.12+)
- Avoid `Any` type - use explicit types
- Annotate all function parameters and return types

[Source: docs/architecture/coding-standards.md#type-hints-backend]

---

### Import Order Standards (Python)

**Correct Import Order:**
```python
# 1. Standard library imports
from datetime import datetime
from typing import List, Optional, Literal
from enum import Enum

# 2. Third-party imports
from motor.motor_asyncio import AsyncIOMotorDatabase
from bson import ObjectId
from pydantic import BaseModel, Field, field_validator

# 3. Local application imports
from src.models.conversation import Conversation, Message, MessageRole
from src.repositories.base import BaseRepository
```

**Verification:**
- Ruff automatically checks import order
- Fix with `ruff check --fix src/`

[Source: docs/architecture/coding-standards.md#import-order-standards]

---

### Backend Enum Usage (MessageRole)

**Python Enum Pattern:**
```python
from enum import Enum

class MessageRole(str, Enum):
    USER = "user"
    ASSISTANT = "assistant"
    SYSTEM = "system"
```

**Benefits:**
- Type safety with mypy
- Pydantic validates enum values automatically
- OpenAPI spec shows allowed values in docs
- Frontend can generate matching TypeScript enum

**Cross-Language Consistency:**
- Python: `MessageRole.USER` (member name: `USER`)
- TypeScript: `MessageRole.User` (member name: `User`)
- JSON value: `"user"` (both serialize to same string)

[Source: docs/architecture/coding-standards.md#backend-enum-usage-python]

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-08 | 1.0 | Story created for Epic 3.2 - Conversation Storage & Retrieval (MongoDB) | Bob (Scrum Master) |

## Dev Agent Record

### Agent Model Used
(To be populated by Dev Agent)

### Debug Log References
(To be populated by Dev Agent)

### Completion Notes List
(To be populated by Dev Agent)

### File List
(To be populated by Dev Agent)

## QA Results
(To be populated by QA Agent)
