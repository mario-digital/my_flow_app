# Story 3.2: Conversation Storage & Retrieval (MongoDB)

## Status
Draft

## Story

**As a** backend developer,
**I want** conversation history stored in MongoDB with message threading,
**so that** users can review past conversations and maintain context.

## Acceptance Criteria

1. **Pydantic models created in `my_flow_api/src/models/conversation.py`:**
   - `Message` model: `role` (Literal["user", "assistant", "system"]), `content` (str), `timestamp` (datetime)
   - `Conversation` model: `id` (ObjectId), `context_id` (ObjectId), `messages` (List[Message]), `created_at`, `updated_at`
   - Validators for role enum and message content length

2. **Repository created in `my_flow_api/src/repositories/conversation_repository.py`:**
   - `ConversationRepository` class with methods (all enforce user isolation):
     - `create_conversation(context_id: str, user_id: str) -> ConversationInDB`
     - `get_conversation_by_id(conversation_id: str, user_id: str) -> Optional[ConversationInDB]`
     - `get_conversations_by_context(context_id: str, user_id: str) -> List[ConversationInDB]`
     - `append_message(conversation_id: str, message: Message, user_id: str) -> ConversationInDB`
     - `get_recent_messages(conversation_id: str, user_id: str, limit: int = 20) -> List[Message]`

3. **MongoDB indexes:**
   - Conversations collection: Index on `context_id`, compound index on `(context_id, updated_at desc)`
   - Efficient retrieval of recent conversations per context

4. **Integration tests created in `my_flow_api/tests/integration/test_conversation_repository.py`:**
   - Tests conversation creation and message appending
   - Tests retrieval of recent messages
   - Tests pagination
   - At least 85% coverage

## Tasks / Subtasks

- [ ] **Task 0: Create Pydantic models for conversations** (AC: 1)
  - [ ] Create `my_flow_api/src/models/conversation.py`
  - [ ] Import required dependencies: `from pydantic import BaseModel, Field, field_validator` and `from datetime import datetime` and `from typing import Literal, List, Optional`
  - [ ] Define `MessageRole` enum class:
    ```python
    from enum import Enum

    class MessageRole(str, Enum):
        USER = "user"
        ASSISTANT = "assistant"
        SYSTEM = "system"
    ```
  - [ ] Define `Message` Pydantic model with fields:
    - `role: MessageRole` - Message sender role
    - `content: str` - Message text content with `Field(min_length=1, max_length=10000)`
    - `timestamp: datetime` - When message was created
  - [ ] Add `model_config` to enable validation and populate by name
  - [ ] Define `ConversationBase` model with common fields:
    - `context_id: str` - Parent context reference
    - `messages: List[Message] = []` - Message history
  - [ ] Define `ConversationCreate` model (inherits `ConversationBase`):
    - `context_id: str` - Required context ID
  - [ ] Define `Conversation` model (inherits `ConversationBase`) with DB fields:
    - `id: str = Field(alias="_id")` - MongoDB ObjectId as string
    - `user_id: str` - Owner of conversation
    - `created_at: datetime`
    - `updated_at: datetime`
  - [ ] Add field validator for `content` to ensure non-empty messages
  - [ ] Follow coding standards (Section 9: Backend Enum Usage)

- [ ] **Task 1: Create conversation repository with base CRUD** (AC: 2)
  - [ ] Create `my_flow_api/src/repositories/conversation_repository.py`
  - [ ] Import required modules:
    ```python
    from motor.motor_asyncio import AsyncIOMotorDatabase
    from bson import ObjectId
    from datetime import datetime
    from typing import Optional, List
    from src.models.conversation import Conversation, Message, ConversationCreate
    from src.repositories.base import BaseRepository
    ```
  - [ ] Create `ConversationRepository` class inheriting from `BaseRepository[Conversation]`
  - [ ] Implement `__init__` method that calls `super().__init__(db, "conversations", Conversation)`
  - [ ] Ensure repository follows repository pattern from backend architecture
  - [ ] Add docstrings to class and all methods

- [ ] **Task 2: Implement create_conversation method** (AC: 2)
  - [ ] Add `async def create_conversation(self, context_id: str, user_id: str) -> Conversation` method
  - [ ] Create document dictionary with:
    - `context_id: str`
    - `user_id: str`
    - `messages: []` (empty list)
    - `created_at: datetime.utcnow()`
    - `updated_at: datetime.utcnow()`
  - [ ] Call `self.collection.insert_one()` to insert document
  - [ ] Fetch inserted document with `self.collection.find_one({"_id": result.inserted_id})`
  - [ ] Convert `_id` ObjectId to string before returning
  - [ ] Return `Conversation` instance constructed from document
  - [ ] Add error handling for database errors

- [ ] **Task 3: Implement get_conversation_by_id method with user isolation** (AC: 2)
  - [ ] Add `async def get_conversation_by_id(self, conversation_id: str, user_id: str) -> Optional[Conversation]` method
  - [ ] **SECURITY: Add `user_id` parameter to enforce user isolation at repository layer**
  - [ ] Convert `conversation_id` string to `ObjectId(conversation_id)`
  - [ ] Call `await self.collection.find_one({"_id": ObjectId(conversation_id), "user_id": user_id})`
  - [ ] **CRITICAL: Include `user_id` in query to prevent cross-user data access**
  - [ ] Return `None` if not found OR if user doesn't own the conversation
  - [ ] Convert `_id` to string and return `Conversation(**doc)` if found
  - [ ] Handle `InvalidId` exception from invalid ObjectId strings

- [ ] **Task 4: Implement get_conversations_by_context method with user isolation** (AC: 2)
  - [ ] Add `async def get_conversations_by_context(self, context_id: str, user_id: str, limit: int = 10) -> List[Conversation]` method
  - [ ] **SECURITY: Add `user_id` parameter to enforce user isolation**
  - [ ] Query: `{"context_id": context_id, "user_id": user_id}`
  - [ ] **CRITICAL: Include both `context_id` AND `user_id` to prevent cross-user access**
  - [ ] Sort by `updated_at` descending (most recent first)
  - [ ] Limit results to `limit` parameter (default 10)
  - [ ] Use `cursor = self.collection.find(query).sort("updated_at", -1).limit(limit)`
  - [ ] Convert cursor to list: `docs = await cursor.to_list(length=limit)`
  - [ ] Convert each doc's `_id` to string
  - [ ] Return list of `Conversation` objects (only those owned by user)

- [ ] **Task 5: Implement append_message method with authorization** (AC: 2)
  - [ ] Add `async def append_message(self, conversation_id: str, message: Message, user_id: str) -> Conversation` method
  - [ ] **SECURITY: Add `user_id` parameter for authorization check**
  - [ ] Create message dict from Pydantic model: `message_dict = message.model_dump()`
  - [ ] Set timestamp in dict (avoid mutating input): `message_dict["timestamp"] = message_dict.get("timestamp") or datetime.utcnow()`
  - [ ] Use atomic `find_one_and_update` to check existence, authorize, and update in one operation:
    ```python
    result = await self.collection.find_one_and_update(
        {"_id": ObjectId(conversation_id), "user_id": user_id},  # Atomic auth check
        {
            "$push": {"messages": message_dict},
            "$set": {"updated_at": datetime.utcnow()}
        },
        return_document=True
    )
    ```
  - [ ] Raise `ValueError("Conversation not found or unauthorized")` if `result is None`
  - [ ] Convert `_id` to string and return `Conversation(**result)`
  - [ ] **CRITICAL: This prevents TOCTOU race condition and enforces authorization atomically**

- [ ] **Task 6: Implement get_recent_messages method with user isolation** (AC: 2)
  - [ ] Add `async def get_recent_messages(self, conversation_id: str, user_id: str, limit: int = 20) -> List[Message]` method
  - [ ] **SECURITY: Add `user_id` parameter to enforce authorization**
  - [ ] Fetch conversation with `get_conversation_by_id(conversation_id, user_id)` (passes user_id for isolation)
  - [ ] Return empty list if conversation not found OR user doesn't own it
  - [ ] Use array slicing to get last `limit` messages: `conversation.messages[-limit:]`
  - [ ] Return list of `Message` objects in chronological order (oldest to newest)
  - [ ] Add docstring explaining message ordering and authorization

- [ ] **Task 7: Add MongoDB indexes for conversations collection with user isolation support** (AC: 3)
  - [ ] Open `my_flow_api/src/database.py`
  - [ ] Locate `create_indexes()` function
  - [ ] Add index creation for conversations collection:
    ```python
    # Conversations collection indexes (user isolation optimized)
    await db.conversations.create_index("user_id")
    await db.conversations.create_index("context_id")
    await db.conversations.create_index([("user_id", 1), ("context_id", 1)])
    await db.conversations.create_index([("context_id", 1), ("updated_at", -1)])
    await db.conversations.create_index([("user_id", 1), ("_id", 1)])
    ```
  - [ ] **CRITICAL: Compound indexes support user isolation queries efficiently**
  - [ ] Ensure indexes are created on app startup
  - [ ] Verify index creation doesn't cause errors if indexes already exist (MongoDB handles this automatically)

- [ ] **Task 8: Write integration tests for conversation creation** (AC: 4)
  - [ ] Create `my_flow_api/tests/integration/test_conversation_repository.py`
  - [ ] Import pytest, pytest fixtures, and required modules
  - [ ] Create pytest fixture `conversation_repo(db)` that returns `ConversationRepository(db)`
  - [ ] Test: `test_create_conversation_success()` - Verifies conversation is created with empty messages
  - [ ] Test: `test_create_conversation_has_timestamps()` - Verifies `created_at` and `updated_at` are set
  - [ ] Test: `test_create_conversation_links_to_context()` - Verifies `context_id` is stored correctly
  - [ ] Use `@pytest.mark.asyncio` decorator for async tests
  - [ ] Clean up test data after each test

- [ ] **Task 9: Write integration tests for message operations** (AC: 4)
  - [ ] Test: `test_append_message_to_conversation()` - Appends message with correct user_id and verifies it's stored
  - [ ] Test: `test_append_multiple_messages()` - Appends 3 messages and verifies order
  - [ ] Test: `test_append_message_updates_timestamp()` - Verifies `updated_at` changes after append
  - [ ] Test: `test_append_message_to_nonexistent_conversation()` - Raises `ValueError` with "not found or unauthorized"
  - [ ] Test: `test_append_message_unauthorized_user()` - **SECURITY**: Wrong user_id raises `ValueError`
  - [ ] Test: `test_append_message_does_not_mutate_input()` - **SECURITY**: Input Message object unchanged after append
  - [ ] Test: `test_get_recent_messages()` - Appends 25 messages, retrieves last 20
  - [ ] Test: `test_get_recent_messages_respects_limit()` - Tests custom limit parameter
  - [ ] Verify messages are returned in chronological order (oldest to newest)

- [ ] **Task 10: Write integration tests for retrieval operations and user isolation** (AC: 4)
  - [ ] Test: `test_get_conversation_by_id()` - Fetches conversation by ID with correct user_id
  - [ ] Test: `test_get_conversation_by_id_not_found()` - Returns None for invalid ID
  - [ ] Test: `test_get_conversation_by_id_wrong_user()` - **SECURITY**: Returns None when user_id doesn't match
  - [ ] Test: `test_get_conversations_by_context()` - Fetches conversations filtered by user_id
  - [ ] Test: `test_get_conversations_by_context_sorted()` - Verifies most recently updated first
  - [ ] Test: `test_get_conversations_by_context_limit()` - Creates 15 conversations, limits to 10
  - [ ] Test: `test_get_conversations_empty_context()` - Returns empty list for context with no conversations
  - [ ] Test: `test_get_conversations_filters_other_users()` - **SECURITY**: Doesn't return other users' conversations
  - [ ] Test: `test_get_recent_messages_wrong_user()` - **SECURITY**: Returns empty list for wrong user_id

- [ ] **Task 11: Write integration tests for message role validation** (AC: 1, 4)
  - [ ] Test: `test_message_role_validation()` - Accepts valid roles (user, assistant, system)
  - [ ] Test: `test_message_role_invalid_value()` - Rejects invalid role string
  - [ ] Test: `test_message_content_length_validation()` - Rejects content > 10000 chars
  - [ ] Test: `test_message_content_empty_validation()` - Rejects empty content string
  - [ ] Use Pydantic's `ValidationError` to catch validation failures
  - [ ] Verify error messages are user-friendly

- [ ] **Task 12: Run tests and verify coverage** (AC: 4)
  - [ ] Run integration tests: `cd my_flow_api && poetry run pytest tests/integration/test_conversation_repository.py -v`
  - [ ] Run coverage: `poetry run pytest tests/integration/test_conversation_repository.py --cov=src/repositories/conversation_repository --cov=src/models/conversation --cov-report=term-missing`
  - [ ] Verify coverage ‚â• 85%
  - [ ] Fix any failing tests or coverage gaps
  - [ ] Document coverage report in story completion notes

- [ ] **Task 13: Code quality and compliance** (AC: All)
  - [ ] Run linter: `cd my_flow_api && poetry run ruff check src/models/conversation.py src/repositories/conversation_repository.py`
  - [ ] Fix any linting errors or warnings
  - [ ] Run type checker: `poetry run mypy src/models/conversation.py src/repositories/conversation_repository.py`
  - [ ] Fix any type errors
  - [ ] Verify import order follows coding standards (stdlib ‚Üí third-party ‚Üí local)
  - [ ] Verify all functions have docstrings with parameter descriptions
  - [ ] Verify exception handling follows standards (Section 5: Error Handling)
  - [ ] Verify all async functions use proper async/await patterns

## Dev Notes

### Previous Story Insights

Story 3.1 created the AI service layer with streaming support for OpenAI and Anthropic. The `Message` model defined in this story (3.2) will be used by the AI service's `stream_chat_response()` method. Ensure compatibility with the `List[Message]` parameter expected by `AIService.stream_chat_response()`.

[Source: docs/stories/3.1.story.md]

---

### Data Models: Conversation & Message

**Conversation Model:**
- `id`: string (MongoDB ObjectId) - Unique identifier
- `context_id`: string (MongoDB ObjectId) - Parent context reference
- `user_id`: string - Owner (from Logto JWT)
- `messages`: Message[] - Array of message objects
- `created_at`: datetime - Creation timestamp
- `updated_at`: datetime - Last modification timestamp

**Message Structure:**
```python
class MessageRole(str, Enum):
    USER = "user"
    ASSISTANT = "assistant"
    SYSTEM = "system"

class Message(BaseModel):
    role: MessageRole
    content: str = Field(min_length=1, max_length=10000)
    timestamp: datetime
```

**Key Points:**
- Messages are embedded documents within conversations (not separate collection)
- Message order preserved in array (chronological)
- `updated_at` changes whenever new message appended
- Future: `metadata` field for `flow_ids` and `tokens_used` (Story 3.3)

[Source: docs/architecture/data-models.md#conversation-model]

---

### MongoDB Indexes for Conversations (User Isolation Optimized)

**Required Indexes:**
```python
# Conversations collection (optimized for user isolation)
await db.conversations.create_index("user_id")
await db.conversations.create_index("context_id")
await db.conversations.create_index([("user_id", 1), ("context_id", 1)])
await db.conversations.create_index([("context_id", 1), ("updated_at", -1)])
await db.conversations.create_index([("user_id", 1), ("_id", 1)])
```

**Index Purposes:**
- `user_id`: Fast user-level filtering (critical for isolation)
- `context_id`: Context-based lookups
- `(user_id, context_id)`: **User isolation compound index** - supports `get_conversations_by_context()`
- `(context_id, updated_at desc)`: Sorted retrieval of recent conversations
- `(user_id, _id)`: **User isolation for get_by_id** - supports `get_conversation_by_id()`

**Performance & Security:**
- **User Isolation Queries:** Compound indexes on `(user_id, ...)` support efficient user-filtered queries
- **Query Pattern:** `{user_id: "user123", context_id: "ctx456"}` uses `(user_id, context_id)` index
- **Get by ID Pattern:** `{user_id: "user123", _id: ObjectId(...)}` uses `(user_id, _id)` index
- Descending order (`-1`) for `updated_at` returns most recent first
- All queries automatically filtered by user_id for security

**Index Selection Examples:**
```python
# Uses (user_id, context_id) index
db.conversations.find({"user_id": "user123", "context_id": "ctx456"})

# Uses (user_id, _id) index
db.conversations.find({"user_id": "user123", "_id": ObjectId("...")})

# Uses (context_id, updated_at) index + user_id filter
db.conversations.find({
    "user_id": "user123",
    "context_id": "ctx456"
}).sort("updated_at", -1)
```

[Source: docs/architecture/data-models.md#database-indexes-mongodb, MongoDB Compound Index Documentation]

---

### Repository Pattern: Conversation Repository

**Repository Layer Responsibilities:**
- Encapsulate MongoDB CRUD operations
- Return Pydantic model instances (not raw dicts)
- Handle ObjectId ‚Üî string conversions
- Provide query methods with filters and pagination

**ConversationRepository Methods (All Enforce User Isolation):**
```python
class ConversationRepository(BaseRepository[Conversation]):
    async def create_conversation(context_id: str, user_id: str) -> Conversation
    async def get_conversation_by_id(conversation_id: str, user_id: str) -> Optional[Conversation]
    async def get_conversations_by_context(context_id: str, user_id: str, limit: int = 10) -> List[Conversation]
    async def append_message(conversation_id: str, message: Message, user_id: str) -> Conversation
    async def get_recent_messages(conversation_id: str, user_id: str, limit: int = 20) -> List[Message]
```

**Key Patterns:**
- Inherit from `BaseRepository[Conversation]` for common CRUD
- Override or extend methods as needed
- **üîí CRITICAL: ALL methods include `user_id` parameter for defense-in-depth security**
- Use `$push` operator for appending messages to array
- Use `find_one_and_update(..., return_document=True)` for atomic updates
- Convert `_id` ObjectId to string before returning to caller
- **üîí Include `user_id` in ALL queries to prevent cross-user data access**

[Source: docs/architecture/backend-architecture.md#repository-layer-data-access]

---

### User Isolation & Defense-in-Depth Security

**Security Principle: Repository Layer MUST Enforce User Isolation**

Never rely solely on service layer authorization - enforce user ownership at the data access layer for defense-in-depth.

**Why Repository-Level Authorization?**
- **Defense in Depth:** Service layer bugs won't expose cross-user data
- **Fail-Safe:** If service forgets to check user_id, repository still protects
- **Audit Trail:** Clear authorization at every data access point
- **Prevents Privilege Escalation:** Malicious/buggy service can't bypass authorization

**User Isolation Pattern:**
```python
# ‚úÖ CORRECT: User isolation enforced at repository layer
async def get_conversation_by_id(
    self,
    conversation_id: str,
    user_id: str  # Required for authorization
) -> Optional[Conversation]:
    doc = await self.collection.find_one({
        "_id": ObjectId(conversation_id),
        "user_id": user_id  # Prevents cross-user access
    })
    return Conversation(**doc) if doc else None

# ‚úÖ CORRECT: List operations also filtered by user_id
async def get_conversations_by_context(
    self,
    context_id: str,
    user_id: str  # Required for authorization
) -> List[Conversation]:
    docs = await self.collection.find({
        "context_id": context_id,
        "user_id": user_id  # Only returns user's own conversations
    }).to_list(length=100)
    return [Conversation(**doc) for doc in docs]
```

**Anti-Pattern (INSECURE):**
```python
# ‚ùå WRONG: Relies on service layer for authorization
async def get_conversation_by_id(
    self,
    conversation_id: str  # Missing user_id parameter!
) -> Optional[Conversation]:
    doc = await self.collection.find_one({
        "_id": ObjectId(conversation_id)
        # Missing user_id filter - cross-user access possible!
    })
    return Conversation(**doc) if doc else None

# Service layer authorization (fragile)
async def service_get_conversation(conv_id: str, user_id: str):
    conv = await repo.get_conversation_by_id(conv_id)  # No user check!
    if conv and conv.user_id != user_id:  # Authorization AFTER fetch
        raise Unauthorized()
    return conv
# Problem: Data already fetched from DB. Race conditions possible.
# Problem: If service forgets this check, data leaks occur.
```

**Benefits of Repository-Level User Isolation:**

1. **Impossible to Bypass:** Service layer can't accidentally expose cross-user data
2. **Consistent Security:** All data access automatically filtered by user
3. **Performance:** Query optimization with user_id in compound indexes
4. **Auditable:** Single enforcement point in codebase
5. **Testable:** Repository tests verify user isolation directly

**Index Support for User Isolation:**
```python
# Compound indexes support user isolation queries efficiently
await db.conversations.create_index([("user_id", 1), ("context_id", 1)])
await db.conversations.create_index([("user_id", 1), ("_id", 1)])

# Queries use these indexes for fast user-filtered lookups
db.conversations.find({"user_id": "user123", "context_id": "ctx456"})  # Uses index
```

**Testing User Isolation:**
- Create conversations for different users
- Verify user A cannot fetch user B's conversations
- Verify user A cannot append messages to user B's conversations
- Verify list operations only return user's own data

[Source: OWASP Defense in Depth, MongoDB Security Best Practices]

**Atomic Message Append with Authorization:**
```python
# Prepare message dict (avoid mutating input parameter)
message_dict = message.model_dump()
message_dict["timestamp"] = message_dict.get("timestamp") or datetime.utcnow()

# Atomic find + auth check + update in single operation
result = await self.collection.find_one_and_update(
    {"_id": ObjectId(conversation_id), "user_id": user_id},  # Authorization filter
    {
        "$push": {"messages": message_dict},
        "$set": {"updated_at": datetime.utcnow()}
    },
    return_document=True
)

if result is None:
    raise ValueError("Conversation not found or unauthorized")
```

**Why use `$push`:**
- Atomic operation - no race conditions
- Appends to end of array (maintains chronological order)
- Concurrent message appends are safe

**Why use `find_one_and_update`:**
- Returns updated document in single DB roundtrip
- `return_document=True` returns document AFTER update
- Avoids separate `find_one()` call after update
- **SECURITY: Combining auth check in query prevents TOCTOU race condition**

**Security Best Practices:**
- ‚úÖ Include `user_id` in query filter for atomic authorization
- ‚úÖ Avoid mutating input parameters (create dict copy)
- ‚úÖ Set timestamp in dict, not on input object
- ‚ùå Never separate authorization check from update (TOCTOU vulnerability)

**TOCTOU (Time-of-Check-Time-of-Use) Prevention:**
```python
# ‚ùå WRONG: Race condition vulnerability
conversation = await self.get_conversation_by_id(conversation_id)  # Check
if conversation.user_id != user_id:
    raise ValueError("Unauthorized")
await self.collection.update_one(...)  # Use (user could change in between)

# ‚úÖ CORRECT: Atomic authorization in single operation
result = await self.collection.find_one_and_update(
    {"_id": ObjectId(conversation_id), "user_id": user_id},  # Atomic check + use
    ...
)
```

[Source: Motor documentation, MongoDB array operators, OWASP Security Patterns]

---

### Array Slicing for Recent Messages

**Getting Last N Messages:**
```python
# Python list slicing (in-memory)
conversation.messages[-limit:]  # Last 'limit' messages

# MongoDB projection (future optimization)
await db.conversations.find_one(
    {"_id": ObjectId(conversation_id)},
    {"messages": {"$slice": -20}}  # Last 20 messages only
)
```

**Current Approach (Story 3.2):**
- Fetch entire conversation, slice in Python
- Simple and works for MVP (< 100 messages per conversation)

**Future Optimization (if needed):**
- Use MongoDB `$slice` projection to fetch only last N messages
- Reduces network transfer for long conversations (> 500 messages)
- Implement if performance profiling shows bottleneck

[Source: docs/architecture/backend-architecture.md#repository-layer]

---

### Pydantic Model Configuration

**Pydantic Settings Pattern:**
```python
from pydantic import BaseModel, Field, ConfigDict

class Conversation(BaseModel):
    id: str = Field(alias="_id")
    context_id: str
    user_id: str
    messages: List[Message] = []
    created_at: datetime
    updated_at: datetime

    model_config = ConfigDict(
        populate_by_name=True,  # Allows both 'id' and '_id' as input
        json_encoders={datetime: lambda v: v.isoformat()}
    )
```

**Key Configuration:**
- `alias="_id"`: Maps MongoDB `_id` field to Python `id` attribute
- `populate_by_name=True`: Accepts both `id` and `_id` in input data
- `json_encoders`: Serializes datetime to ISO 8601 strings for JSON responses

[Source: docs/architecture/backend-architecture.md#pydantic-models]

---

### Error Handling for Repositories

**Repository Error Patterns:**
```python
# Invalid ObjectId
try:
    obj_id = ObjectId(conversation_id)
except InvalidId:
    raise ValueError(f"Invalid conversation ID: {conversation_id}")

# Document not found
conversation = await self.get_conversation_by_id(conversation_id)
if not conversation:
    raise ValueError(f"Conversation not found: {conversation_id}")

# Database errors
try:
    await self.collection.insert_one(doc)
except PyMongoError as e:
    logger.error(f"Failed to create conversation: {e}")
    raise
```

**Error Handling Standards:**
- Raise `ValueError` for invalid input (caller's fault)
- Re-raise `PyMongoError` for database errors (system fault)
- Log errors server-side with context
- Never expose internal error details to API responses

[Source: docs/architecture/coding-standards.md#error-handling-standards]

---

### Async/Await Patterns for MongoDB

**Motor (Async MongoDB Driver):**
```python
# ‚úÖ CORRECT: Use await for all Motor operations
result = await self.collection.insert_one(doc)
doc = await self.collection.find_one({"_id": obj_id})
cursor = self.collection.find(query)
docs = await cursor.to_list(length=100)

# ‚ùå WRONG: Forgetting await
doc = self.collection.find_one({"_id": obj_id})  # Returns coroutine, not doc!
```

**Key Points:**
- All Motor database operations return coroutines (must use `await`)
- Cursors are synchronous but `.to_list()` is async
- Use `async def` for all repository methods
- Enable `pytest-asyncio` for testing async methods

[Source: docs/architecture/tech-stack.md#database-driver, Motor documentation]

---

### File Locations (Project Structure)

**Files to Create:**
- `my_flow_api/src/models/conversation.py` - Pydantic models
- `my_flow_api/src/repositories/conversation_repository.py` - Repository implementation
- `my_flow_api/tests/integration/test_conversation_repository.py` - Integration tests

**Files to Modify:**
- `my_flow_api/src/database.py` - Add conversation collection indexes

**Files to Reference (DO NOT MODIFY):**
- `my_flow_api/src/repositories/base.py` - BaseRepository pattern
- `my_flow_api/src/database.py` - Database connection setup
- `docs/architecture/data-models.md` - Conversation model specification

[Source: docs/architecture/source-tree.md#backend-structure]

---

## Testing

### Test File Organization

**Integration Tests:**
```
my_flow_api/tests/integration/
‚îî‚îÄ‚îÄ test_conversation_repository.py
```

**Why Integration Tests (not Unit Tests):**
- Repository layer interacts directly with MongoDB
- Mocking MongoDB would test mock behavior, not real DB operations
- Integration tests catch index issues, query performance, schema mismatches
- Requires test MongoDB instance (Docker or MongoDB Atlas free tier)

[Source: docs/architecture/13-testing-strategy.md#test-organization]

---

### Pytest Configuration for Integration Tests

**pytest.ini settings:**
```ini
[pytest]
testpaths = tests
asyncio_mode = auto  # Auto-detect async tests
markers =
    integration: Integration tests (DB, external services)
```

**Test Fixtures:**
```python
import pytest
from motor.motor_asyncio import AsyncIOMotorClient
from src.database import get_database

@pytest.fixture
async def db():
    """Test database fixture."""
    client = AsyncIOMotorClient("mongodb://localhost:27017")
    db = client["myflow_test"]
    yield db
    # Cleanup: Drop test database after tests
    await client.drop_database("myflow_test")
    client.close()

@pytest.fixture
def conversation_repo(db):
    """ConversationRepository fixture."""
    return ConversationRepository(db)
```

**Running Integration Tests:**
```bash
# Run all integration tests
poetry run pytest tests/integration/ -v

# Run specific test file
poetry run pytest tests/integration/test_conversation_repository.py -v

# Run with coverage
poetry run pytest tests/integration/ --cov=src/repositories --cov=src/models --cov-report=term-missing
```

[Source: docs/architecture/13-testing-strategy.md#backend-tests]

---

### Coverage Requirements

**Target Coverage:**
- **Repository:** ‚â• 85% line coverage
- **Pydantic Models:** ‚â• 80% (validators, serialization)

**Coverage Thresholds:**
```bash
pytest --cov=src/repositories/conversation_repository \
       --cov=src/models/conversation \
       --cov-report=term-missing \
       --cov-fail-under=85
```

**What to Test:**
- All repository methods (create, read, update)
- Pydantic validators (role enum, content length)
- Error handling (invalid IDs, not found, validation errors)
- Edge cases (empty conversations, message limits, pagination)

[Source: docs/architecture/13-testing-strategy.md#test-coverage-requirements]

---

### Type Hints and mypy

**Critical Type Hints:**
```python
# All functions must have complete type annotations
async def get_conversation_by_id(self, conversation_id: str) -> Optional[Conversation]:
    ...

async def get_conversations_by_context(self, context_id: str, limit: int = 10) -> List[Conversation]:
    ...

async def append_message(self, conversation_id: str, message: Message) -> Conversation:
    ...
```

**mypy Strict Mode:**
- Run `mypy src/models/conversation.py src/repositories/conversation_repository.py`
- Use `str | None` instead of `Optional[str]` (Python 3.12+)
- Avoid `Any` type - use explicit types
- Annotate all function parameters and return types

[Source: docs/architecture/coding-standards.md#type-hints-backend]

---

### Import Order Standards (Python)

**Correct Import Order:**
```python
# 1. Standard library imports
from datetime import datetime
from typing import List, Optional, Literal
from enum import Enum

# 2. Third-party imports
from motor.motor_asyncio import AsyncIOMotorDatabase
from bson import ObjectId
from pydantic import BaseModel, Field, field_validator

# 3. Local application imports
from src.models.conversation import Conversation, Message, MessageRole
from src.repositories.base import BaseRepository
```

**Verification:**
- Ruff automatically checks import order
- Fix with `ruff check --fix src/`

[Source: docs/architecture/coding-standards.md#import-order-standards]

---

### Backend Enum Usage (MessageRole)

**Python Enum Pattern:**
```python
from enum import Enum

class MessageRole(str, Enum):
    USER = "user"
    ASSISTANT = "assistant"
    SYSTEM = "system"
```

**Benefits:**
- Type safety with mypy
- Pydantic validates enum values automatically
- OpenAPI spec shows allowed values in docs
- Frontend can generate matching TypeScript enum

**Cross-Language Consistency:**
- Python: `MessageRole.USER` (member name: `USER`)
- TypeScript: `MessageRole.User` (member name: `User`)
- JSON value: `"user"` (both serialize to same string)

[Source: docs/architecture/coding-standards.md#backend-enum-usage-python]

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-08 | 1.0 | Story created for Epic 3.2 - Conversation Storage & Retrieval (MongoDB) | Bob (Scrum Master) |
| 2025-10-08 | 1.1 | Security improvements: Added user_id authorization to append_message, fixed TOCTOU race condition, prevented input mutation | Bob (Scrum Master) |
| 2025-10-08 | 1.2 | Defense-in-depth: Enforced user isolation at repository layer for ALL methods, added compound indexes for user-filtered queries, added comprehensive security tests | Bob (Scrum Master) |

## Dev Agent Record

### Agent Model Used
(To be populated by Dev Agent)

### Debug Log References
(To be populated by Dev Agent)

### Completion Notes List
(To be populated by Dev Agent)

### File List
(To be populated by Dev Agent)

## QA Results
(To be populated by QA Agent)
