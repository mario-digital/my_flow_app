# Story 5.0: Docker Containerization & Production Infrastructure

## Status
Draft

## Story

**As a** developer,
**I want** Docker containerization for both frontend and backend with professional multi-stage builds,
**so that** I can ensure consistent deployment across all environments and follow production-ready DevOps best practices.

## Acceptance Criteria

1. **Backend Dockerfile created (`my_flow_api/Dockerfile`):**
   - Multi-stage build (builder → production)
   - Uses Python 3.12 slim base image
   - Health check configured (`/health` endpoint)
   - Non-root user for security
   - `.dockerignore` excludes unnecessary files
   - Optimized layer caching (dependencies before code)
   - Production image < 300MB

2. **Backend development Dockerfile created (`my_flow_api/Dockerfile.dev`):**
   - Development-optimized configuration
   - Hot reload support with volume mounts
   - Includes dev dependencies (pytest, ruff, mypy)
   - Faster build times for iteration

3. **Frontend Dockerfile created (`my_flow_client/Dockerfile`):**
   - Multi-stage build (deps → builder → runner)
   - Uses Node 20 Alpine base image
   - Next.js standalone output for minimal size
   - Health check configured
   - Non-root user for security
   - `.dockerignore` excludes node_modules, .next
   - Production image < 200MB

4. **Frontend development Dockerfile created (`my_flow_client/Dockerfile.dev`):**
   - Development-optimized configuration
   - Hot reload support with volume mounts
   - Faster build times for iteration

5. **docker-compose.yml created at root:**
   - Orchestrates frontend, backend, and Redis services
   - Local development configuration
   - Named volumes for Redis data persistence
   - Network configuration for service communication
   - Environment variable management
   - Health checks for all services

6. **docker-compose.prod.yml created at root:**
   - Production-like local configuration
   - Uses production Dockerfiles
   - Demonstrates production deployment setup
   - Can be used for pre-deployment testing

7. **.dockerignore files created:**
   - Backend: Excludes `.venv/`, `__pycache__/`, `.pytest_cache/`, `*.pyc`, `.git/`
   - Frontend: Excludes `node_modules/`, `.next/`, `.git/`, `*.md`

8. **Environment configuration updated:**
   - `.env.template` documents all required variables
   - Backend supports `REDIS_URL` environment variable
   - Frontend BFF pattern preserved (no architecture changes)
   - Authentication flow unchanged (Logto + JWT)

9. **Redis integration:**
   - Local: Redis container in docker-compose (development)
   - Production: Upstash Redis (serverless, free tier)
   - Backend code prepared for `REDIS_URL` configuration
   - Caching layer ready for Story 5.2

10. **Documentation updated:**
    - README.md includes Docker setup instructions
    - Docker commands documented (build, run, logs, stop)
    - Architecture diagram shows containerized deployment
    - Production deployment guide added

11. **CI/CD compatibility:**
    - GitHub Actions can build Docker images
    - Existing CI workflows unchanged (native testing)
    - Optional: Docker-based CI workflow (bonus)

12. **Health check endpoints implemented:**
    - Backend: `GET /health` returns `{"status": "ok", "db": "connected", "cache": "connected"}`
    - Frontend: Next.js built-in health check
    - Used by Docker HEALTHCHECK and deployment platforms

## Tasks / Subtasks

- [ ] **Task 0: Create backend Dockerfile for production** (AC: 1)
  - [ ] Create `my_flow_api/Dockerfile`:
    ```dockerfile
    # Multi-stage build for production
    # Stage 1: Builder
    FROM python:3.12-slim AS builder

    # Install uv for faster dependency installation
    COPY --from=ghcr.io/astral-sh/uv:latest /uv /bin/uv

    WORKDIR /app

    # Copy dependency files first (better caching)
    COPY pyproject.toml uv.lock ./

    # Install dependencies into /app/.venv
    RUN uv sync --frozen --no-dev

    # Stage 2: Production runtime
    FROM python:3.12-slim AS runtime

    WORKDIR /app

    # Install curl for health checks (adds ~2MB but more reliable)
    RUN apt-get update && apt-get install -y --no-install-recommends curl && \
        rm -rf /var/lib/apt/lists/*

    # Copy virtual environment from builder
    COPY --from=builder /app/.venv /app/.venv

    # Copy application code
    COPY src/ ./src/

    # Create non-root user
    RUN useradd --create-home --shell /bin/bash appuser && \
        chown -R appuser:appuser /app

    USER appuser

    # Add .venv to PATH
    ENV PATH="/app/.venv/bin:$PATH"

    # Health check (using curl for reliability)
    HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
      CMD curl -f http://localhost:8000/health || exit 1

    # Expose port
    EXPOSE 8000

    # Start application
    CMD ["uvicorn", "src.main:app", "--host", "0.0.0.0", "--port", "8000"]
    ```
  - [ ] Verify multi-stage build reduces image size
  - [ ] Test health check works correctly

- [ ] **Task 1: Create backend development Dockerfile** (AC: 2)
  - [ ] Create `my_flow_api/Dockerfile.dev`:
    ```dockerfile
    FROM python:3.12-slim

    # Install uv
    COPY --from=ghcr.io/astral-sh/uv:latest /uv /bin/uv

    WORKDIR /app

    # Install all dependencies (including dev)
    COPY pyproject.toml uv.lock ./
    RUN uv sync --frozen

    # Don't copy code (will be mounted as volume)

    ENV PATH="/app/.venv/bin:$PATH"

    EXPOSE 8000

    # Use uvicorn with --reload for hot reload
    CMD ["uvicorn", "src.main:app", "--host", "0.0.0.0", "--port", "8000", "--reload"]
    ```
  - [ ] Test hot reload works with volume mount
  - [ ] Verify dev dependencies are installed

- [ ] **Task 2: Create backend .dockerignore** (AC: 7)
  - [ ] Create `my_flow_api/.dockerignore`:
    ```
    .venv/
    __pycache__/
    *.pyc
    *.pyo
    *.pyd
    .pytest_cache/
    .ruff_cache/
    .mypy_cache/
    .coverage
    htmlcov/
    .git/
    .gitignore
    *.md
    .env
    .env.*
    tests/
    ```
  - [ ] Verify exclusions work (check image size reduction)

- [ ] **Task 3: Create frontend Dockerfile for production** (AC: 3)
  - [ ] Create `my_flow_client/Dockerfile`:
    ```dockerfile
    # Multi-stage build for production
    # Stage 1: Dependencies
    FROM node:20-alpine AS deps

    WORKDIR /app

    # Install Bun
    RUN npm install -g bun

    # Copy package files
    COPY package.json bun.lockb ./

    # Install dependencies
    RUN bun install --frozen-lockfile

    # Stage 2: Builder
    FROM node:20-alpine AS builder

    WORKDIR /app

    # Install Bun
    RUN npm install -g bun

    # Copy dependencies from deps stage
    COPY --from=deps /app/node_modules ./node_modules
    COPY . .

    # Build Next.js app (standalone output)
    ENV NEXT_TELEMETRY_DISABLED 1
    RUN bun run build

    # Stage 3: Production runner
    FROM node:20-alpine AS runner

    WORKDIR /app

    ENV NODE_ENV production
    ENV NEXT_TELEMETRY_DISABLED 1

    # Create non-root user
    RUN addgroup --system --gid 1001 nodejs && \
        adduser --system --uid 1001 nextjs

    # Copy standalone output
    COPY --from=builder --chown=nextjs:nodejs /app/.next/standalone ./
    COPY --from=builder --chown=nextjs:nodejs /app/.next/static ./.next/static
    COPY --from=builder --chown=nextjs:nodejs /app/public ./public

    USER nextjs

    EXPOSE 3000

    ENV PORT 3000
    ENV HOSTNAME "0.0.0.0"

    # Health check (with error handling)
    HEALTHCHECK --interval=30s --timeout=3s --start-period=10s --retries=3 \
      CMD node -e "require('http').get('http://localhost:3000/api/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)}).on('error', () => process.exit(1))"

    CMD ["node", "server.js"]
    ```
  - [ ] Update `my_flow_client/next.config.js` to enable standalone output:
    ```javascript
    /** @type {import('next').NextConfig} */
    const nextConfig = {
      output: 'standalone',
      // ... existing config
    };

    module.exports = nextConfig;
    ```
  - [ ] Verify multi-stage build produces < 200MB image
  - [ ] Test standalone output works correctly

- [ ] **Task 4: Create frontend development Dockerfile** (AC: 4)
  - [ ] Create `my_flow_client/Dockerfile.dev`:
    ```dockerfile
    FROM node:20-alpine

    WORKDIR /app

    # Install Bun
    RUN npm install -g bun

    # Copy package files
    COPY package.json bun.lockb ./

    # Install dependencies
    RUN bun install

    # Don't copy code (will be mounted as volume)

    EXPOSE 3000

    # Use bun dev for hot reload
    CMD ["bun", "run", "dev"]
    ```
  - [ ] Test hot reload works with volume mount

- [ ] **Task 5: Create frontend .dockerignore** (AC: 7)
  - [ ] Create `my_flow_client/.dockerignore`:
    ```
    node_modules/
    .next/
    out/
    .git/
    .gitignore
    *.md
    .env*.local
    .vercel/
    coverage/
    .turbo/
    __tests__/
    e2e/
    *.test.ts
    *.test.tsx
    *.spec.ts
    ```
  - [ ] Verify exclusions work (check image size reduction)

- [ ] **Task 6: Create docker-compose.yml for local development** (AC: 5)
  - [ ] Create `docker-compose.yml` at root:
    ```yaml
    version: '3.9'

    services:
      backend:
        build:
          context: ./my_flow_api
          dockerfile: Dockerfile.dev
        ports:
          - "8000:8000"
        environment:
          - MONGODB_URI=${MONGODB_URI}
          - REDIS_URL=redis://redis:6379
          - LOGTO_ENDPOINT=${LOGTO_ENDPOINT}
          - LOGTO_APP_ID=${LOGTO_APP_ID}
          - LOGTO_APP_SECRET=${LOGTO_APP_SECRET}
        volumes:
          - ./my_flow_api/src:/app/src:ro
        depends_on:
          redis:
            condition: service_healthy
        networks:
          - myflow-network
        healthcheck:
          test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
          interval: 10s
          timeout: 3s
          retries: 3
          start_period: 5s

      frontend:
        build:
          context: ./my_flow_client
          dockerfile: Dockerfile.dev
        ports:
          - "3000:3000"
        environment:
          - NEXT_PUBLIC_API_URL=http://localhost:8000
          - NEXT_PUBLIC_LOGTO_ENDPOINT=${NEXT_PUBLIC_LOGTO_ENDPOINT}
          - NEXT_PUBLIC_LOGTO_APP_ID=${NEXT_PUBLIC_LOGTO_APP_ID}
          - LOGTO_APP_SECRET=${LOGTO_APP_SECRET}
          - LOGTO_COOKIE_SECRET=${LOGTO_COOKIE_SECRET}
          - NEXT_PUBLIC_BASE_URL=http://localhost:3000
          - NEXT_PUBLIC_LOGTO_RESOURCE=${NEXT_PUBLIC_LOGTO_RESOURCE}
        volumes:
          - ./my_flow_client/src:/app/src:ro
          - ./my_flow_client/public:/app/public:ro
        depends_on:
          - backend
        networks:
          - myflow-network

      redis:
        image: redis:7-alpine
        ports:
          - "6379:6379"
        volumes:
          - redis_data:/data
        networks:
          - myflow-network
        healthcheck:
          test: ["CMD", "redis-cli", "ping"]
          interval: 5s
          timeout: 3s
          retries: 5
        command: redis-server --appendonly yes

    volumes:
      redis_data:
        driver: local

    networks:
      myflow-network:
        driver: bridge
    ```
  - [ ] Test all services start successfully
  - [ ] Verify hot reload works for both frontend and backend
  - [ ] Test Redis connectivity from backend

- [ ] **Task 7: Create docker-compose.prod.yml for production testing** (AC: 6)
  - [ ] Create `docker-compose.prod.yml` at root:
    ```yaml
    version: '3.9'

    services:
      backend:
        build:
          context: ./my_flow_api
          dockerfile: Dockerfile
        ports:
          - "8000:8000"
        environment:
          - MONGODB_URI=${MONGODB_URI}
          - REDIS_URL=${REDIS_URL:-redis://redis:6379}
          - LOGTO_ENDPOINT=${LOGTO_ENDPOINT}
          - LOGTO_APP_ID=${LOGTO_APP_ID}
          - LOGTO_APP_SECRET=${LOGTO_APP_SECRET}
        depends_on:
          redis:
            condition: service_healthy
        networks:
          - myflow-network
        restart: unless-stopped

      frontend:
        build:
          context: ./my_flow_client
          dockerfile: Dockerfile
        ports:
          - "3000:3000"
        environment:
          - NEXT_PUBLIC_API_URL=http://backend:8000
          - NEXT_PUBLIC_LOGTO_ENDPOINT=${NEXT_PUBLIC_LOGTO_ENDPOINT}
          - NEXT_PUBLIC_LOGTO_APP_ID=${NEXT_PUBLIC_LOGTO_APP_ID}
          - LOGTO_APP_SECRET=${LOGTO_APP_SECRET}
          - LOGTO_COOKIE_SECRET=${LOGTO_COOKIE_SECRET}
          - NEXT_PUBLIC_BASE_URL=${NEXT_PUBLIC_BASE_URL}
          - NEXT_PUBLIC_LOGTO_RESOURCE=${NEXT_PUBLIC_LOGTO_RESOURCE}
        depends_on:
          - backend
        networks:
          - myflow-network
        restart: unless-stopped

      redis:
        image: redis:7-alpine
        volumes:
          - redis_data:/data
        networks:
          - myflow-network
        restart: unless-stopped

    volumes:
      redis_data:

    networks:
      myflow-network:
    ```
  - [ ] Test production builds work correctly
  - [ ] Verify image sizes meet requirements (backend < 300MB, frontend < 200MB)
  - [ ] Test restart policies work

- [ ] **Task 8: Create backend health check endpoint** (AC: 12)
  - [ ] Create `my_flow_api/src/routers/health.py`:
    ```python
    from fastapi import APIRouter, status
    from src.database import get_database

    router = APIRouter()

    @router.get("/health", status_code=status.HTTP_200_OK)
    async def health_check():
        """
        Health check endpoint for Docker and deployment platforms.

        Returns:
            dict: Health status including database and cache connectivity
        """
        health_status = {
            "status": "ok",
            "db": "unknown",
            "cache": "unknown"
        }

        # Check MongoDB connection
        try:
            db = get_database()
            await db.command("ping")
            health_status["db"] = "connected"
        except Exception:
            health_status["db"] = "disconnected"
            health_status["status"] = "degraded"

        # Check Redis connection (if configured)
        try:
            import os
            redis_url = os.getenv("REDIS_URL")
            if redis_url:
                import redis.asyncio as redis
                redis_client = redis.from_url(redis_url)
                await redis_client.ping()
                health_status["cache"] = "connected"
            else:
                health_status["cache"] = "not_configured"
        except Exception:
            health_status["cache"] = "disconnected"
            health_status["status"] = "degraded"

        return health_status
    ```
  - [ ] Register health router in `my_flow_api/src/main.py`:
    ```python
    from src.routers.health import router as health_router

    app.include_router(health_router, tags=["health"])
    ```
  - [ ] Test health endpoint returns correct status
  - [ ] Test health endpoint with MongoDB disconnected
  - [ ] Test health endpoint with Redis disconnected

- [ ] **Task 9: Create frontend health check endpoint** (AC: 12)
  - [ ] Create `my_flow_client/src/app/api/health/route.ts`:
    ```typescript
    import { NextResponse } from 'next/server';

    export async function GET() {
      return NextResponse.json({ status: 'ok' }, { status: 200 });
    }
    ```
  - [ ] Test health endpoint returns 200 OK

- [ ] **Task 10: Update .env.template with Docker variables** (AC: 8)
  - [ ] Update `.env.template` to include Docker-specific variables:
    ```bash
    # ========================================
    # MongoDB Atlas (Cloud Database)
    # ========================================
    op://MyFlow/MongoDB/MONGODB_URI

    # ========================================
    # Redis Configuration
    # ========================================
    # Local development (Docker): redis://redis:6379
    # Production: Upstash Redis URL (from Upstash dashboard)
    op://MyFlow/Redis/REDIS_URL

    # ========================================
    # Logto Authentication
    # ========================================
    op://MyFlow/Logto/LOGTO_ENDPOINT
    op://MyFlow/Logto/LOGTO_APP_ID
    op://MyFlow/Logto/LOGTO_APP_SECRET
    op://MyFlow/Logto/LOGTO_COOKIE_SECRET
    op://MyFlow/Logto/NEXT_PUBLIC_LOGTO_ENDPOINT
    op://MyFlow/Logto/NEXT_PUBLIC_LOGTO_APP_ID
    op://MyFlow/Logto/NEXT_PUBLIC_LOGTO_RESOURCE

    # ========================================
    # Frontend Configuration
    # ========================================
    # Local: http://localhost:3000
    # Production: https://your-app.vercel.app
    op://MyFlow/Frontend/NEXT_PUBLIC_BASE_URL

    # Local Docker: http://backend:8000
    # Production: https://your-api.railway.app
    op://MyFlow/Frontend/NEXT_PUBLIC_API_URL

    # ========================================
    # AI Provider (OpenAI or Anthropic)
    # ========================================
    op://MyFlow/AI/OPENAI_API_KEY
    # OR
    op://MyFlow/AI/ANTHROPIC_API_KEY
    ```
  - [ ] Document Docker-specific environment variable usage in comments

- [ ] **Task 11: Update README.md with Docker instructions** (AC: 10)
  - [ ] Add Docker section to README.md:
    ```markdown
    ## Docker Setup

    ### Prerequisites
    - Docker Desktop (includes Docker Compose)
    - 1Password CLI for secret management

    ### Local Development with Docker

    1. **Start all services:**
       ```bash
       # Inject secrets and start containers
       op run --env-file=.env.template -- docker-compose up
       ```

    2. **View logs:**
       ```bash
       # All services
       docker-compose logs -f

       # Specific service
       docker-compose logs -f backend
       docker-compose logs -f frontend
       docker-compose logs -f redis
       ```

    3. **Stop services:**
       ```bash
       docker-compose down

       # Stop and remove volumes
       docker-compose down -v
       ```

    ### Production Testing with Docker

    ```bash
    # Build and run production images
    op run --env-file=.env.template -- docker-compose -f docker-compose.prod.yml up --build
    ```

    ### Docker Commands Reference

    | Command | Description |
    |---------|-------------|
    | `docker-compose up` | Start all services |
    | `docker-compose up -d` | Start in background (detached) |
    | `docker-compose down` | Stop all services |
    | `docker-compose logs -f <service>` | View logs for service |
    | `docker-compose build` | Rebuild images |
    | `docker-compose ps` | List running services |
    | `docker-compose exec <service> sh` | Shell into service |

    ### Health Checks

    - **Backend**: http://localhost:8000/health
    - **Frontend**: http://localhost:3000/api/health
    - **Redis**: `docker-compose exec redis redis-cli ping`

    ### Docker Image Sizes

    - Backend: < 300MB (production)
    - Frontend: < 200MB (production)
    - Redis: ~32MB (Alpine base)
    ```
  - [ ] Test all documented commands work correctly

- [ ] **Task 12: Add optional Docker CI workflow** (AC: 11)
  - [ ] Create `.github/workflows/docker-ci.yml`:
    ```yaml
    name: Docker CI

    on:
      pull_request:
        branches: [main]
      push:
        branches: [main]

    jobs:
      docker-build-test:
        runs-on: ubuntu-latest
        steps:
          - name: Checkout code
            uses: actions/checkout@v4

          - name: Set up Docker Buildx
            uses: docker/setup-buildx-action@v3

          - name: Build backend Docker image
            uses: docker/build-push-action@v5
            with:
              context: ./my_flow_api
              file: ./my_flow_api/Dockerfile
              push: false
              tags: myflow-backend:test
              cache-from: type=gha
              cache-to: type=gha,mode=max

          - name: Build frontend Docker image
            uses: docker/build-push-action@v5
            with:
              context: ./my_flow_client
              file: ./my_flow_client/Dockerfile
              push: false
              tags: myflow-frontend:test
              cache-from: type=gha
              cache-to: type=gha,mode=max

          - name: Verify image sizes
            run: |
              backend_size=$(docker images myflow-backend:test --format "{{.Size}}")
              frontend_size=$(docker images myflow-frontend:test --format "{{.Size}}")
              echo "Backend image size: $backend_size"
              echo "Frontend image size: $frontend_size"
    ```
  - [ ] Test workflow runs successfully on PR
  - [ ] Verify image size reporting works

- [ ] **Task 13: Create production deployment guide** (AC: 10)
  - [ ] Create `docs/deployment/docker-deployment.md`:
    ```markdown
    # Docker Deployment Guide

    ## Production Architecture

    ```
    ┌─────────────┐         ┌──────────────────┐         ┌─────────────┐
    │   Vercel    │         │     Railway      │         │  Upstash    │
    │  (Frontend) │────────>│    (Backend)     │────────>│  (Redis)    │
    └─────────────┘         └──────────────────┘         └─────────────┘
           │                         │                          │
           │                         └──────────────────────────┘
           │                         MongoDB Atlas (Database)
           └─────────────────────────────────────────────────────>
    ```

    ## Railway Backend Deployment

    1. **Create new project in Railway**
    2. **Connect GitHub repository**
    3. **Configure environment variables** (from 1Password):
       - MONGODB_URI
       - REDIS_URL (from Upstash)
       - LOGTO_ENDPOINT
       - LOGTO_APP_ID
       - LOGTO_APP_SECRET
    4. **Railway auto-detects Dockerfile and deploys**
    5. **Health check**: `https://your-app.railway.app/health`

    ## Vercel Frontend Deployment

    1. **Import GitHub repository to Vercel**
    2. **Configure environment variables**:
       - NEXT_PUBLIC_API_URL (Railway backend URL)
       - NEXT_PUBLIC_LOGTO_ENDPOINT
       - NEXT_PUBLIC_LOGTO_APP_ID
       - LOGTO_APP_SECRET
       - LOGTO_COOKIE_SECRET
       - NEXT_PUBLIC_BASE_URL
       - NEXT_PUBLIC_LOGTO_RESOURCE
    3. **Vercel auto-detects Next.js and deploys**
    4. **Configure custom domain** (optional)

    ## Upstash Redis Setup

    1. **Create free Upstash account**: https://upstash.com
    2. **Create new Redis database** (free tier)
    3. **Copy REST URL** to `REDIS_URL` environment variable
    4. **Use in Railway backend deployment**

    ## MongoDB Atlas Configuration

    1. **Whitelist Railway IP addresses** (or use 0.0.0.0/0)
    2. **Enable backups** (automatic in free tier)
    3. **Monitor database size** (stay within 512MB free tier)

    ## Rollback Strategy

    - **Railway**: Redeploy previous version via Railway dashboard
    - **Vercel**: Revert deployment via Vercel dashboard
    - **Database**: Use Atlas automatic backups (restore to specific time)

    ## Monitoring

    - **Railway**: Built-in logs and metrics dashboard
    - **Vercel**: Analytics and deployment logs
    - **Health checks**: Monitor `/health` endpoints
    - **Uptime monitoring**: Use UptimeRobot or similar (free tier)
    ```
  - [ ] Verify deployment guide is complete and accurate

- [ ] **Task 14: Test complete Docker workflow** (AC: All)
  - [ ] Clean environment test:
    ```bash
    # Remove all containers and volumes
    docker-compose down -v

    # Rebuild and start fresh
    op run --env-file=.env.template -- docker-compose up --build
    ```
  - [ ] Verify all services start successfully
  - [ ] Test backend health check: http://localhost:8000/health
  - [ ] Test frontend health check: http://localhost:3000/api/health
  - [ ] Test Redis connectivity: `docker-compose exec redis redis-cli ping`
  - [ ] Test hot reload for backend (modify Python file)
  - [ ] Test hot reload for frontend (modify React component)
  - [ ] Test production build:
    ```bash
    docker-compose -f docker-compose.prod.yml up --build
    ```
  - [ ] Verify production image sizes meet requirements
  - [ ] Test stopping and restarting services
  - [ ] Test volume persistence (Redis data survives restart)

- [ ] **Task 15: Code quality and linting** (AC: All)
  - [ ] Verify all Dockerfiles follow best practices:
    - [ ] Multi-stage builds minimize image size
    - [ ] Non-root users for security
    - [ ] Health checks configured
    - [ ] Layer caching optimized (dependencies before code)
    - [ ] Proper .dockerignore files
  - [ ] Run Hadolint (Docker linter) if available:
    ```bash
    docker run --rm -i hadolint/hadolint < my_flow_api/Dockerfile
    docker run --rm -i hadolint/hadolint < my_flow_client/Dockerfile
    ```
  - [ ] Verify docker-compose.yml syntax:
    ```bash
    docker-compose config
    docker-compose -f docker-compose.prod.yml config
    ```
  - [ ] Test all environment variables are documented

## Dev Notes

### Architecture Compliance

**From `docs/architecture/tech-stack.md`:**
- ✅ **No architecture changes**: Docker is packaging only, not modifying tech stack
- ✅ **Backend**: Python 3.12+, FastAPI, Motor (MongoDB), uv (dependency management)
- ✅ **Frontend**: Next.js 15, React 19, Bun (package manager)
- ✅ **Database**: MongoDB Atlas (cloud, unchanged)
- ✅ **Cache**: Redis (new) - local container for dev, Upstash for production
- ✅ **Authentication**: Logto (unchanged) - BFF pattern preserved

**From `docs/architecture/coding-standards.md`:**
- ✅ **BFF Pattern**: Frontend NEVER calls FastAPI directly - preserved in Docker
- ✅ **JWT Tokens**: Server-side only (Next.js API routes) - unchanged
- ✅ **Environment Variables**: Managed via `.env.template` + 1Password CLI
- ✅ **Secret Management**: 1Password CLI (`op run`) works with Docker Compose

**From `docs/architecture/9-unified-project-structure.md`:**
- ✅ **Monorepo Structure**: Docker added at root, does not change workspace structure
- ✅ **CI/CD**: Existing workflows unchanged, Docker CI is optional addition
- ✅ **Development Workflow**: `bun run dev` still works, Docker is alternative option

### Critical Docker Best Practices

**Multi-Stage Builds:**
- Stage 1 (Builder): Install dependencies, build artifacts
- Stage 2 (Runtime): Copy only necessary files, minimal image
- Reduces production image size by 50-70%

**Layer Caching Optimization:**
```dockerfile
# ❌ WRONG: Code changes invalidate dependency cache
COPY . .
RUN uv sync

# ✅ CORRECT: Dependencies cached separately
COPY pyproject.toml uv.lock ./
RUN uv sync
COPY src/ ./src/
```

**Non-Root Users:**
```dockerfile
# Create user with minimal permissions
RUN useradd --create-home --shell /bin/bash appuser
USER appuser
```

**Health Checks:**
```dockerfile
# Backend: Using curl for reliability
HEALTHCHECK --interval=30s --timeout=3s --retries=3 \
  CMD curl -f http://localhost:8000/health || exit 1

# Frontend: Node.js with error handling
HEALTHCHECK --interval=30s --timeout=3s --retries=3 \
  CMD node -e "require('http').get('http://localhost:3000/api/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)}).on('error', () => process.exit(1))"
```

**Why curl for backend instead of Python urllib?**
- ✅ More reliable (handles connection failures gracefully)
- ✅ Minimal image size impact (~2MB vs ~50ms latency of urllib)
- ✅ Standard tool for health checks in production
- ✅ Works correctly with Docker's 0.0.0.0 binding

**Why error handler for frontend?**
- ✅ Prevents unhandled exceptions if service is down
- ✅ Ensures health check fails properly instead of hanging
- ✅ Production-ready error handling

### Docker Compose Best Practices

**Named Volumes:**
```yaml
volumes:
  redis_data:  # Named volume persists across container restarts
```

**Health Check Dependencies:**
```yaml
depends_on:
  redis:
    condition: service_healthy  # Wait for Redis before starting backend
```

**Network Isolation:**
```yaml
networks:
  myflow-network:  # Isolated network for service communication
```

**Environment Variable Management:**
```yaml
environment:
  - REDIS_URL=redis://redis:6379  # Container-to-container DNS
```

### Redis Integration Strategy

**Local Development:**
- Docker Compose: `redis://redis:6379` (container name DNS)
- Redis 7 Alpine image (~32MB)
- Data persisted in named volume

**Production:**
- Upstash Redis (serverless, free tier)
- REST API (no direct connection needed)
- Auto-scaling, no maintenance

**Backend Configuration:**
```python
import os
redis_url = os.getenv("REDIS_URL")
if redis_url:
    redis_client = redis.from_url(redis_url)
```

### Security Considerations

**What's Protected:**
- ✅ JWT tokens never exposed to browser (BFF pattern preserved)
- ✅ Containers run as non-root users
- ✅ Secrets injected via 1Password CLI (never committed)
- ✅ MongoDB Atlas connection string not in Docker image
- ✅ .dockerignore prevents leaking sensitive files

**Docker-Specific Security:**
- Health checks don't expose internal data
- No hardcoded secrets in Dockerfiles
- Production images exclude dev dependencies
- Network isolation via docker-compose networks

### Performance Optimization

**Image Size Targets:**
- Backend: < 300MB (Python 3.12 slim + dependencies)
- Frontend: < 200MB (Node 20 Alpine + Next.js standalone)
- Redis: ~32MB (Alpine base)

**Build Time Optimization:**
- Layer caching: Dependencies before code
- Multi-stage builds: Parallel build stages
- .dockerignore: Excludes unnecessary files from context

**Runtime Optimization:**
- Next.js standalone output (minimal size)
- Python slim images (no build tools in prod)
- Redis Alpine (minimal memory footprint)

### Development Workflow Impact

**Before Docker:**
```bash
# Terminal 1: Backend
cd my_flow_api && ./dev.sh

# Terminal 2: Frontend
cd my_flow_client && bun run dev
```

**After Docker (Optional):**
```bash
# Single terminal: Both services
op run --env-file=.env.template -- docker-compose up
```

**Key Benefits:**
- ✅ **Consistency**: Same environment across team members
- ✅ **Onboarding**: New devs run one command
- ✅ **Production Parity**: Local Docker matches deployed containers
- ✅ **Flexibility**: Can still use native dev workflow

### Production Deployment Architecture

**Current (Manual):**
```
Frontend: Vercel (manual deploy)
Backend: Manual hosting
Database: MongoDB Atlas
```

**With Docker (Professional):**
```
Frontend: Vercel (Dockerfile-based) or Railway
Backend: Railway (Dockerfile auto-deploy)
Database: MongoDB Atlas (unchanged)
Cache: Upstash Redis (serverless)
```

**Deployment Flow:**
1. Push to `main` branch
2. Railway detects Dockerfile, builds image
3. Railway deploys container to production
4. Vercel builds frontend (Next.js native or Dockerfile)
5. Health checks verify deployment success

### File Locations

**New Files Created:**
```
my_flow_app/
├── my_flow_api/
│   ├── Dockerfile                # Production backend image
│   ├── Dockerfile.dev            # Development backend image
│   ├── .dockerignore             # Exclude files from build context
│   └── src/
│       └── routers/
│           └── health.py         # Health check endpoint
│
├── my_flow_client/
│   ├── Dockerfile                # Production frontend image
│   ├── Dockerfile.dev            # Development frontend image
│   ├── .dockerignore             # Exclude files from build context
│   └── src/
│       └── app/
│           └── api/
│               └── health/
│                   └── route.ts  # Health check endpoint
│
├── docker-compose.yml            # Local development orchestration
├── docker-compose.prod.yml       # Production testing orchestration
├── .env.template                 # Updated with Docker variables
│
├── docs/
│   └── deployment/
│       └── docker-deployment.md  # Production deployment guide
│
└── .github/
    └── workflows/
        └── docker-ci.yml         # Optional Docker CI workflow
```

### Testing Strategy

**From `docs/architecture/13-testing-strategy.md`:**

1. **Unit Tests (Unchanged):**
   - Run natively via `bun test` and `pytest`
   - Faster feedback than Docker-based tests
   - CI/CD uses native testing (existing workflows)

2. **Integration Tests (Enhanced):**
   - Test full stack via `docker-compose up`
   - Verify service-to-service communication
   - Test health check endpoints

3. **Production Testing:**
   - `docker-compose.prod.yml` simulates production environment
   - Verify production image sizes
   - Test deployment readiness

### Employer Portfolio Value

**What This Demonstrates:**

1. **DevOps Skills:**
   - Multi-stage Docker builds (optimization)
   - docker-compose orchestration (service coordination)
   - Production deployment knowledge (Railway/Vercel)

2. **Production Readiness:**
   - Health checks for monitoring
   - Non-root users for security
   - Image size optimization
   - Environment configuration management

3. **Professional Standards:**
   - Documented deployment process
   - Rollback strategy
   - Monitoring and observability
   - Clean separation: dev vs. production

4. **Modern Stack Knowledge:**
   - Container orchestration
   - Serverless Redis (Upstash)
   - Cloud-native deployments
   - CI/CD integration

### Future Enhancements (Not in This Story)

- Kubernetes deployment manifests
- Docker registry (Docker Hub, GitHub Container Registry)
- Automated security scanning (Trivy, Snyk)
- Multi-architecture builds (ARM64 + x86_64)
- Performance monitoring in containers
- Log aggregation (Datadog, CloudWatch)

## Testing

### Manual Testing Checklist

- [ ] Backend Dockerfile builds successfully
- [ ] Backend image size < 300MB
- [ ] Backend health check returns correct status
- [ ] Backend development Dockerfile supports hot reload
- [ ] Frontend Dockerfile builds successfully
- [ ] Frontend image size < 200MB
- [ ] Frontend standalone output works correctly
- [ ] Frontend development Dockerfile supports hot reload
- [ ] docker-compose.yml starts all services successfully
- [ ] docker-compose.prod.yml builds production images
- [ ] Redis container starts and accepts connections
- [ ] Backend can connect to Redis
- [ ] MongoDB Atlas connection works from Docker
- [ ] Logto authentication works (BFF pattern preserved)
- [ ] All health checks pass
- [ ] Volume persistence works (Redis data survives restart)
- [ ] Logs are accessible for all services
- [ ] Environment variables load correctly
- [ ] .dockerignore files exclude correct files
- [ ] Documentation is complete and accurate
- [ ] Optional Docker CI workflow runs successfully

### Automated Testing

**Existing Tests (Unchanged):**
- Backend: `pytest` (native)
- Frontend: `bun test` (native)

**New Docker Tests:**
- Image build verification (GitHub Actions)
- Image size validation
- Health check endpoint tests

**Run Tests:**
```bash
# Native tests (existing)
bun run test

# Docker build tests (new)
docker-compose config  # Validate YAML syntax
docker-compose up --build  # Integration test
```

## Definition of Done

- [ ] All acceptance criteria met
- [ ] All tasks completed
- [ ] Dockerfiles follow best practices (multi-stage, non-root, health checks)
- [ ] Image sizes meet requirements (backend < 300MB, frontend < 200MB)
- [ ] docker-compose.yml tested and working
- [ ] docker-compose.prod.yml tested and working
- [ ] Health check endpoints implemented and tested
- [ ] .dockerignore files created and verified
- [ ] .env.template updated with Docker variables
- [ ] README.md updated with Docker instructions
- [ ] Deployment guide created and verified
- [ ] Optional Docker CI workflow tested
- [ ] All services start successfully
- [ ] Hot reload works in development mode
- [ ] Production builds work correctly
- [ ] BFF authentication pattern preserved (no changes)
- [ ] Existing CI/CD workflows still pass
- [ ] Documentation reviewed and approved
- [ ] Story marked as "Ready for Review"

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-01-18 | 1.0 | Story created in Draft status | Bob (Scrum Master) |
